{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Project - Phase 2 (Destination Suggestion)\n",
    "<div style=\"text-align: center\">\n",
    "<h1 style = \"color: red\"> Sharif University Of Technology</h1>\n",
    "<h2 style = \"color: green\"> DR. Mahdieh Soleymani | DR. MohammadHossein Rohban </h2>\n",
    "<h3 style = \"color: cyan\"> Head of Project: AmirHossein Razlighi <h3>\n",
    "<h3 style = \"color: cyan\"> Designed By: AmirHossein Razlighi, Javad Hezareh, Payam Taebi, Alireza Sakhaei, Ali Banayeean, Yalda Shabanzadeh, Hamidreza Yaghoubi, Alireza Heidari <h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "<img src=\"./images/Uber_research.jpg\" width=\"100%\" height=\"auto\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are a research engineer at Uber and you are asked to design a system that suggests destinations to the passengers. The system should be able to suggest destinations based on the passenger's history. For example, one passenger may save a variety of locations (like home, work, gym, etc.). This passenger may go to gym, often on weekends and when he/she requests a car from Home. \n",
    "\n",
    "So, for example, if I am a student, going to university usually from Saturday to Wednesday on 8:00 from \"home\", the next time I request a car from \"home\" on 8:00, the system should suggest \"university\" as the destination. Now, it's not that simple always, so we should seek for smart wayys to solve this problem!\n",
    "\n",
    "As you may understood by now, we should engineer some of features from the data we have and try to predict the next destination of the passenger.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(2024)\n",
    "np.random.seed(2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Approach: Using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you should prepare the data for KNN. You should load the dataset file that we provided, named `Data/output.json` and then clean it, do all the required preprocessings and then split into train-test-val sets if necessary. Note that we provided a splitted test set for you, named `Data/output_test.json`. You should not use this file for training or validation. You should only use it for testing your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin lat</th>\n",
       "      <th>origin lon</th>\n",
       "      <th>dest lat</th>\n",
       "      <th>dest lon</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>36.000</td>\n",
       "      <td>51.085</td>\n",
       "      <td>13:07:00</td>\n",
       "      <td>14:43:00</td>\n",
       "      <td>43.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.000</td>\n",
       "      <td>51.085</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>15:13:00</td>\n",
       "      <td>16:49:00</td>\n",
       "      <td>36.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "      <td>35.745</td>\n",
       "      <td>51.465</td>\n",
       "      <td>20:41:00</td>\n",
       "      <td>20:54:00</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.745</td>\n",
       "      <td>51.465</td>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "      <td>21:24:00</td>\n",
       "      <td>21:37:00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>35.680</td>\n",
       "      <td>51.445</td>\n",
       "      <td>23:38:00</td>\n",
       "      <td>23:58:00</td>\n",
       "      <td>19.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day  origin lat  origin lon  dest lat  dest lon start_time  \\\n",
       "0        0    0      35.625      51.375    36.000    51.085   13:07:00   \n",
       "1        0    0      36.000      51.085    35.625    51.375   15:13:00   \n",
       "2        0    0      35.680      51.445    35.745    51.465   20:41:00   \n",
       "3        0    0      35.745      51.465    35.680    51.445   21:24:00   \n",
       "4        0    1      35.625      51.375    35.680    51.445   23:38:00   \n",
       "\n",
       "   end_time  price  \n",
       "0  14:43:00  43.99  \n",
       "1  16:49:00  36.66  \n",
       "2  20:54:00  15.08  \n",
       "3  21:37:00  10.00  \n",
       "4  23:58:00  19.48  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"datasets/output.json\")\n",
    "df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], format=\"%H:%M:%S\").dt.time\n",
    "df[\"end_time\"] = pd.to_datetime(df[\"end_time\"], format=\"%H:%M:%S\").dt.time\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin lat</th>\n",
       "      <th>origin lon</th>\n",
       "      <th>dest lat</th>\n",
       "      <th>dest lon</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>35.650</td>\n",
       "      <td>51.225</td>\n",
       "      <td>35.640</td>\n",
       "      <td>51.270</td>\n",
       "      <td>11:58:00</td>\n",
       "      <td>12:12:00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.250</td>\n",
       "      <td>35.690</td>\n",
       "      <td>51.295</td>\n",
       "      <td>21:58:00</td>\n",
       "      <td>22:18:00</td>\n",
       "      <td>11.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>35.650</td>\n",
       "      <td>51.225</td>\n",
       "      <td>35.865</td>\n",
       "      <td>51.045</td>\n",
       "      <td>20:05:00</td>\n",
       "      <td>20:58:00</td>\n",
       "      <td>23.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>35.875</td>\n",
       "      <td>51.375</td>\n",
       "      <td>35.890</td>\n",
       "      <td>51.315</td>\n",
       "      <td>17:39:00</td>\n",
       "      <td>18:17:00</td>\n",
       "      <td>13.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>35.625</td>\n",
       "      <td>51.375</td>\n",
       "      <td>35.650</td>\n",
       "      <td>51.385</td>\n",
       "      <td>13:16:00</td>\n",
       "      <td>13:19:00</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day  origin lat  origin lon  dest lat  dest lon start_time  \\\n",
       "0       24    6      35.650      51.225    35.640    51.270   11:58:00   \n",
       "1       46    2      35.625      51.250    35.690    51.295   21:58:00   \n",
       "2       27    5      35.650      51.225    35.865    51.045   20:05:00   \n",
       "3        7    4      35.875      51.375    35.890    51.315   17:39:00   \n",
       "4       27    3      35.625      51.375    35.650    51.385   13:16:00   \n",
       "\n",
       "   end_time  price  \n",
       "0  12:12:00  10.00  \n",
       "1  22:18:00  11.84  \n",
       "2  20:58:00  23.36  \n",
       "3  18:17:00  13.74  \n",
       "4  13:19:00  15.08  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_json(\"datasets/output_test.json\")\n",
    "test_df[\"start_time\"] = pd.to_datetime(test_df[\"start_time\"], format=\"%H:%M:%S\").dt.time\n",
    "test_df[\"end_time\"] = pd.to_datetime(test_df[\"end_time\"], format=\"%H:%M:%S\").dt.time\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the number of unique users and also randomly select one user\n",
    "num_users = df[\"user_id\"].nunique()\n",
    "selected_user = df[\"user_id\"].sample().iloc[0]\n",
    "num_users, selected_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl import KeplerGl\n",
    "\n",
    "# Uncomment the following line if you are using Google Colab\n",
    "# from google.colab import output\n",
    "# output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin lat</th>\n",
       "      <th>origin lon</th>\n",
       "      <th>dest lat</th>\n",
       "      <th>dest lon</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14698</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>35.905</td>\n",
       "      <td>51.035</td>\n",
       "      <td>35.875</td>\n",
       "      <td>51.125</td>\n",
       "      <td>06:57:00</td>\n",
       "      <td>07:14:00</td>\n",
       "      <td>19.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14699</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>35.875</td>\n",
       "      <td>51.125</td>\n",
       "      <td>35.975</td>\n",
       "      <td>51.250</td>\n",
       "      <td>17:12:00</td>\n",
       "      <td>17:43:00</td>\n",
       "      <td>23.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14700</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>35.975</td>\n",
       "      <td>51.250</td>\n",
       "      <td>35.875</td>\n",
       "      <td>51.125</td>\n",
       "      <td>06:28:00</td>\n",
       "      <td>07:03:00</td>\n",
       "      <td>17.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14701</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>35.875</td>\n",
       "      <td>51.125</td>\n",
       "      <td>35.945</td>\n",
       "      <td>51.170</td>\n",
       "      <td>13:49:00</td>\n",
       "      <td>14:03:00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14702</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>35.945</td>\n",
       "      <td>51.170</td>\n",
       "      <td>35.875</td>\n",
       "      <td>51.125</td>\n",
       "      <td>14:33:00</td>\n",
       "      <td>14:54:00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  Day  origin lat  origin lon  dest lat  dest lon start_time  \\\n",
       "14698       50    0      35.905      51.035    35.875    51.125   06:57:00   \n",
       "14699       50    0      35.875      51.125    35.975    51.250   17:12:00   \n",
       "14700       50    1      35.975      51.250    35.875    51.125   06:28:00   \n",
       "14701       50    1      35.875      51.125    35.945    51.170   13:49:00   \n",
       "14702       50    1      35.945      51.170    35.875    51.125   14:33:00   \n",
       "\n",
       "       end_time  price  \n",
       "14698  07:14:00  19.38  \n",
       "14699  17:43:00  23.11  \n",
       "14700  07:03:00  17.73  \n",
       "14701  14:03:00  10.00  \n",
       "14702  14:54:00  10.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the data related to the randomly selected user\n",
    "# show destinations of this user on map\n",
    "# You should Use Kepler.gl to visualize the data\n",
    "\n",
    "user_df = df[df[\"user_id\"] == selected_user]\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffbf815ecb04c78bf7109347e4ef30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'destinations':        dest lat  dest lon\n",
       "14698    35.875    51.125\n",
       "14699    35.975    51.250\n",
       "1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample output:\n",
    "visualized_trip = KeplerGl(height=400, data = {\"destinations\": user_df[[\"dest lat\", \"dest lon\"]]})\n",
    "visualized_trip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you should do feature engineering stuff! Extract the features that you think are important. Split the features into training set and also extract the related outputs (used for our model further). These outputs may be strings (name of destination) or destination's latitude/longitude or etc. Use your creativity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df[\"start_time\"] = df[\"start_time\"].apply(lambda x: x.hour * 60 + x.minute)\n",
    "test_df[\"start_time\"] = test_df[\"start_time\"].apply(lambda x: x.hour * 60 + x.minute)\n",
    "\n",
    "features = [\"user_id\", \"Day\", \"origin lat\", \"origin lon\", \"start_time\"]\n",
    "outputs = [\"dest lat\", \"dest lon\"]\n",
    "\n",
    "train_X = df[features]\n",
    "train_y = df[outputs]\n",
    "\n",
    "test_X = test_df[features]\n",
    "test_y = test_df[outputs]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X)\n",
    "test_X_scaled = scaler.transform(test_X)\n",
    "\n",
    "train_y_scaled = train_y.to_numpy()\n",
    "test_y_scaled = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17994, 5), (17994, 2), (4499, 5), (4499, 2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out the shape of the train and test dataframes\n",
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to implement our KNN model. For further information on how KNN works, please refer to [this](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) link. As you can see, it's a simple algorithm. We will start with this and see the results of our _destination suggestion_ system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "class NearestNeighbor():\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "        self.train_X = None\n",
    "        self.train_y = None\n",
    "    \n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    def fit(self, train_X, train_y):\n",
    "        self.train_X = train_X\n",
    "        self.train_y = train_y\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        distances = [self.euclidean_distance(test_X, x) for x in self.train_X]\n",
    "        k_idx = np.argsort(distances)[:self.k]\n",
    "        k_labels = [list(self.train_y[i]) for i in k_idx]\n",
    "        return max(k_labels, key=k_labels.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on training data\n",
    "knn = NearestNeighbor()\n",
    "knn.fit(train_X_scaled, train_y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17994/17994 [12:48<00:00, 23.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9179726575525176"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuracy on training data\n",
    "pred_y = []\n",
    "for x in tqdm(train_X_scaled):\n",
    "    pred_y.append(knn.predict(x))\n",
    "    \n",
    "accuracy = sum(np.all(train_y_scaled == pred_y, axis=1)) / len(train_y_scaled)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4499/4499 [03:12<00:00, 23.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4661035785730162"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuracy on test data\n",
    "pred_y = []\n",
    "for x in tqdm(test_X_scaled):\n",
    "    pred_y.append(knn.predict(x))\n",
    "    \n",
    "accuracy = sum(np.all(test_y_scaled == pred_y, axis=1)) / len(test_y_scaled)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: What do you think about this approach? Is it a good idea to use KNN for this problem? Why (or why not)? If the patterns in our datatset (passengers' history) get more complicated, will our model be robust to it in comparison to other models?\n",
    "\n",
    "Your Answer: As we know k-NN is a lazy learner and it doesn't learn a function so that we can predict labels with it. It also doesn't perform well when our dataset is too large or too noisy. Inputs in this problem are a bit complicated and they have many features so, i think that k-NN is not a good approach that we have taken for this problem. We also can see from the calculated accuracies that it doesn't even perform well on this simple dataset that we have, so the results will definitely be worse if we use a more complicated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Approach: Using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we are going to use XGBoost to predict the next destination of the passenger. You can use `xgboost` library to implement this model. To learn more about XGBoost, please refer to [this](https://en.wikipedia.org/wiki/XGBoost) link. It should be familiar to you, as you saw decision trees in the class.\n",
    "\n",
    "For this part, you can use the same data (that you did all the processes on) from the previous part. Or, if you need, you can reload the dataset and do new preprocessings on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the overview of how XGBoost works in the image below:\n",
    "\n",
    "<dev style=\"text-align: center\">\n",
    "<img src=\"./images/XGBoost.png\" />\n",
    "</dev>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, this is for more information and you **do not** need to implement `XGBoost` from scratch. You can use the library that we mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from xgboost) (1.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Defining the model\n",
    "\n",
    "class Encoder():\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "\n",
    "    def fit(self, y):\n",
    "        for col in y.columns:\n",
    "            col_enc = LabelEncoder()\n",
    "            col_enc.fit(y[col])\n",
    "            self.encoders[col] = col_enc\n",
    "                \n",
    "    def transform(self, y):\n",
    "        y_enc = y.copy()\n",
    "        for col, encoder in self.encoders.items():\n",
    "            y_enc[col] = encoder.transform(y[col])\n",
    "        return y_enc\n",
    "\n",
    "    def inverse_transform(self, y):\n",
    "        y_dec = y.copy()\n",
    "        for col, encoder in self.encoders.items():\n",
    "            y_dec[col] = encoder.inverse_transform(y[col])\n",
    "        return y_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "\n",
    "train_y_com = pd.DataFrame(train_y.apply(lambda x: f\"{x['dest lat']}_{x['dest lon']}\", axis=1), columns=[\"dest\"])\n",
    "test_y_com = pd.DataFrame(test_y.apply(lambda x: f\"{x['dest lat']}_{x['dest lon']}\", axis=1), columns=[\"dest\"])\n",
    "encoder.fit(train_y_com)\n",
    "\n",
    "train_y_enc = encoder.transform(train_y_com).to_numpy()\n",
    "test_y_enc = encoder.transform(test_y_com).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the training and test data\n",
    "# and fit the model on training data\n",
    "train_X_enc = train_X_scaled\n",
    "test_X_enc = test_X_scaled\n",
    "\n",
    "classifier = xgb.XGBClassifier()\n",
    "classifier.fit(train_X_enc, train_y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9392019562076248"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out train-data accuracy\n",
    "accuracy = classifier.score(train_X_enc, train_y_enc)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.659924427650589"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out test-data accuracy\n",
    "accuracy = classifier.score(test_X_enc, test_y_enc)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: What do you think about this approach? Is it a good idea to use XGBoost for this problem? Why (or why not)? If the patterns in our dataset (passengers' history) get more complicated, will our model be robust to it in comparison to other models?\n",
    "\n",
    "Your Answer: It's clear from the accuracies that XGBoost is a much more reliable way to solve this problem than the k-NN. It can handle a much more complicated dataset and we can most of the times encode our labels to make them proper for XGBoost. But the problem that XGBoost has is overfitting. Even though its accuracy is much higher on the test set compared to k-NN, we still can see there is a big gap between train set and test set accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Please explain the problem of overfitting in XGBoost. How can you solve it? Provide a brief explanation.\n",
    "\n",
    "Your Answer: So we know that XGBoost is a combination of decision trees and gradient descent methods. We create a decision tree for the errors in every iteration and then we add it to the previous ones. In this step we include a factor called learning rate and we multiply the newly created tree by it before adding the tree to the previous ones. With this factor we can make the steps that are taken towards the goal smaller and by that we can prevent overfitting to some levels. Another factor that causes the overfitting is the depth of the three that we create in every iteration. We know it from the decision trees that if we create a quite deep tree to predict our model we will probably have overfitting problems, So we can also choose a proper depth for our trees to further prevent overfitting.\n",
    "\n",
    "Overall even though we have some ways to prevent our model to overfit, there are some models and levels of complexity that none of the mentioned ways are enough to prevent the overfitting problem. We will either have pretty bad predications and result or we will overfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Approach: Classifier Using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, we are going to use a classifier using neural networks. You can think of this approach and how to model the problem as a classification problem in many ways! So, we are not going to restrict your creativity. Just a hint: You can consider each of the unique destinations (in whole dataset) as a class and then train a classifier to classify the destinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the data for our neural network. Again, you should extract required features from the dataset and then split the dataset into train-test-val sets if necessary. For your ease, we prepared another version of `output.json` that helps you to extract features for this part, easier. So, please load `Data/trip_data.json` and use it for training set and validation set. You should use `Data/trip_data_test.json` for testing your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[work, [35.625, 51.375]]</td>\n",
       "      <td>[restaurant, [36.0, 51.085]]</td>\n",
       "      <td>13:07:00</td>\n",
       "      <td>14:43:00</td>\n",
       "      <td>43.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[restaurant, [36.0, 51.085]]</td>\n",
       "      <td>[work, [35.625, 51.375]]</td>\n",
       "      <td>15:13:00</td>\n",
       "      <td>16:49:00</td>\n",
       "      <td>36.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[home, [35.68, 51.445]]</td>\n",
       "      <td>[restaurant, [35.745, 51.465]]</td>\n",
       "      <td>20:41:00</td>\n",
       "      <td>20:54:00</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[restaurant, [35.745, 51.465]]</td>\n",
       "      <td>[home, [35.68, 51.445]]</td>\n",
       "      <td>21:24:00</td>\n",
       "      <td>21:37:00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[work, [35.625, 51.375]]</td>\n",
       "      <td>[home, [35.68, 51.445]]</td>\n",
       "      <td>23:38:00</td>\n",
       "      <td>23:58:00</td>\n",
       "      <td>19.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day                          origin  \\\n",
       "0        0    0        [work, [35.625, 51.375]]   \n",
       "1        0    0    [restaurant, [36.0, 51.085]]   \n",
       "2        0    0         [home, [35.68, 51.445]]   \n",
       "3        0    0  [restaurant, [35.745, 51.465]]   \n",
       "4        0    1        [work, [35.625, 51.375]]   \n",
       "\n",
       "                      destination start_time  end_time  price  \n",
       "0    [restaurant, [36.0, 51.085]]   13:07:00  14:43:00  43.99  \n",
       "1        [work, [35.625, 51.375]]   15:13:00  16:49:00  36.66  \n",
       "2  [restaurant, [35.745, 51.465]]   20:41:00  20:54:00  15.08  \n",
       "3         [home, [35.68, 51.445]]   21:24:00  21:37:00  10.00  \n",
       "4         [home, [35.68, 51.445]]   23:38:00  23:58:00  19.48  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the training dataset\n",
    "df = pd.read_json(\"datasets/trip_data.json\")\n",
    "df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], format=\"%H:%M:%S\").dt.time\n",
    "df[\"end_time\"] = pd.to_datetime(df[\"end_time\"], format=\"%H:%M:%S\").dt.time\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>[pool, [35.65, 51.225]]</td>\n",
       "      <td>[home, [35.64, 51.27]]</td>\n",
       "      <td>11:58:00</td>\n",
       "      <td>12:12:00</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>[university, [35.625, 51.25]]</td>\n",
       "      <td>[restaurant, [35.69, 51.295]]</td>\n",
       "      <td>21:58:00</td>\n",
       "      <td>22:18:00</td>\n",
       "      <td>11.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>[pool, [35.65, 51.225]]</td>\n",
       "      <td>[restaurant, [35.865, 51.045]]</td>\n",
       "      <td>20:05:00</td>\n",
       "      <td>20:58:00</td>\n",
       "      <td>23.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>[work, [35.875, 51.375]]</td>\n",
       "      <td>[home, [35.89, 51.315]]</td>\n",
       "      <td>17:39:00</td>\n",
       "      <td>18:17:00</td>\n",
       "      <td>13.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>[work, [35.625, 51.375]]</td>\n",
       "      <td>[restaurant, [35.65, 51.385]]</td>\n",
       "      <td>13:16:00</td>\n",
       "      <td>13:19:00</td>\n",
       "      <td>15.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day                         origin  \\\n",
       "0       24    6        [pool, [35.65, 51.225]]   \n",
       "1       46    2  [university, [35.625, 51.25]]   \n",
       "2       27    5        [pool, [35.65, 51.225]]   \n",
       "3        7    4       [work, [35.875, 51.375]]   \n",
       "4       27    3       [work, [35.625, 51.375]]   \n",
       "\n",
       "                      destination start_time  end_time  price  \n",
       "0          [home, [35.64, 51.27]]   11:58:00  12:12:00  10.00  \n",
       "1   [restaurant, [35.69, 51.295]]   21:58:00  22:18:00  11.84  \n",
       "2  [restaurant, [35.865, 51.045]]   20:05:00  20:58:00  23.36  \n",
       "3         [home, [35.89, 51.315]]   17:39:00  18:17:00  13.74  \n",
       "4   [restaurant, [35.65, 51.385]]   13:16:00  13:19:00  15.08  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the test dataset\n",
    "test_df = pd.read_json(\"datasets/trip_data_test.json\")\n",
    "test_df[\"start_time\"] = pd.to_datetime(test_df[\"start_time\"], format=\"%H:%M:%S\").dt.time\n",
    "test_df[\"end_time\"] = pd.to_datetime(test_df[\"end_time\"], format=\"%H:%M:%S\").dt.time\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>work_35.625_51.375</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>restaurant_36.0_51.085</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>home_35.68_51.445</td>\n",
       "      <td>1241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>restaurant_35.745_51.465</td>\n",
       "      <td>1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>work_35.625_51.375</td>\n",
       "      <td>1418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day                    origin  start_time\n",
       "0        0    0        work_35.625_51.375         787\n",
       "1        0    0    restaurant_36.0_51.085         913\n",
       "2        0    0         home_35.68_51.445        1241\n",
       "3        0    0  restaurant_35.745_51.465        1284\n",
       "4        0    1        work_35.625_51.375        1418"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features and do preprocessing if needed\n",
    "combined_origin = df[\"origin\"].values\n",
    "combined_dest = df[\"destination\"].values\n",
    "origin = []\n",
    "for co in combined_origin:\n",
    "    origin.append(f\"{co[0]}_{co[1][0]}_{co[1][1]}\")\n",
    "df[\"origin\"] = origin\n",
    "dest = []\n",
    "for cd in combined_dest:\n",
    "    dest.append(f\"{cd[0]}\")\n",
    "df[\"destination\"] = dest\n",
    "\n",
    "df[\"start_time\"] = df[\"start_time\"].apply(lambda x: x.hour * 60 + x.minute)\n",
    "df[\"end_time\"] = df[\"end_time\"].apply(lambda x: x.hour * 60 + x.minute)\n",
    "\n",
    "features = [\"user_id\", \"Day\", \"origin\", \"start_time\"]\n",
    "outputs = [\"destination\"]\n",
    "\n",
    "train_X = df[features]\n",
    "train_y = df[outputs]\n",
    "\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>Day</th>\n",
       "      <th>origin</th>\n",
       "      <th>start_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>pool_35.65_51.225</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>university_35.625_51.25</td>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>pool_35.65_51.225</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>work_35.875_51.375</td>\n",
       "      <td>1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>work_35.625_51.375</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  Day                   origin  start_time\n",
       "0       24    6        pool_35.65_51.225         718\n",
       "1       46    2  university_35.625_51.25        1318\n",
       "2       27    5        pool_35.65_51.225        1205\n",
       "3        7    4       work_35.875_51.375        1059\n",
       "4       27    3       work_35.625_51.375         796"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features and do preprocessing if needed\n",
    "combined_origin = test_df[\"origin\"].values\n",
    "combined_dest = test_df[\"destination\"].values\n",
    "origin = []\n",
    "for co in combined_origin:\n",
    "   origin.append(f\"{co[0]}_{co[1][0]}_{co[1][1]}\")\n",
    "test_df[\"origin\"] = origin\n",
    "dest = []\n",
    "for cd in combined_dest:\n",
    "    dest.append(f\"{cd[0]}\")\n",
    "test_df[\"destination\"] = dest\n",
    "\n",
    "test_df[\"start_time\"] = test_df[\"start_time\"].apply(lambda x: x.hour * 60 + x.minute)\n",
    "test_df[\"end_time\"] = test_df[\"end_time\"].apply(lambda x: x.hour * 60 + x.minute)\n",
    "\n",
    "\n",
    "features = [\"user_id\", \"Day\", \"origin\", \"start_time\"]\n",
    "outputs = [\"destination\"]\n",
    "\n",
    "test_X = test_df[features]\n",
    "test_y = test_df[outputs]\n",
    "\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: user_id\n",
      "Unique values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "========================================\n",
      "Column: Day\n",
      "Unique values: [0, 1, 2, 3, 4, 5, 6]\n",
      "========================================\n",
      "Column: origin\n",
      "Unique values: ['gym_35.525_51.46', 'gym_35.55_51.165', 'gym_35.575_51.245', 'gym_35.8_51.1', 'gym_35.975_51.25', 'home_35.505_51.06', 'home_35.535_51.305', 'home_35.53_51.485', 'home_35.545_51.095', 'home_35.545_51.145', 'home_35.54_51.075', 'home_35.555_51.18', 'home_35.595_51.475', 'home_35.5_51.29', 'home_35.615_51.175', 'home_35.62_51.275', 'home_35.635_51.39', 'home_35.635_51.47', 'home_35.64_51.25', 'home_35.64_51.27', 'home_35.675_51.25', 'home_35.68_51.215', 'home_35.68_51.445', 'home_35.69_51.12', 'home_35.71_51.09', 'home_35.735_51.2', 'home_35.745_51.465', 'home_35.76_51.435', 'home_35.775_51.4', 'home_35.77_51.245', 'home_35.785_51.435', 'home_35.7_51.115', 'home_35.7_51.21', 'home_35.805_51.225', 'home_35.81_51.11', 'home_35.81_51.5', 'home_35.825_51.32', 'home_35.83_51.185', 'home_35.845_51.235', 'home_35.84_51.13', 'home_35.84_51.24', 'home_35.855_51.32', 'home_35.865_51.24', 'home_35.875_51.4', 'home_35.89_51.315', 'home_35.905_51.035', 'home_35.93_51.235', 'home_35.945_51.085', 'home_35.945_51.415', 'home_35.95_51.225', 'home_35.95_51.28', 'home_35.97_51.21', 'home_35.99_51.295', 'home_35.9_51.215', 'home_35.9_51.35', 'home_35.9_51.495', 'park_35.5_51.0', 'park_35.5_51.5', 'park_36.0_51.0', 'park_36.0_51.5', 'pool_35.525_51.1', 'pool_35.575_51.15', 'pool_35.65_51.225', 'pool_35.725_51.3', 'pool_35.8_51.375', 'restaurant_35.505_51.18', 'restaurant_35.51_51.155', 'restaurant_35.52_51.285', 'restaurant_35.54_51.5', 'restaurant_35.55_51.185', 'restaurant_35.565_51.06', 'restaurant_35.56_51.415', 'restaurant_35.575_51.42', 'restaurant_35.59_51.47', 'restaurant_35.65_51.26', 'restaurant_35.65_51.385', 'restaurant_35.675_51.31', 'restaurant_35.68_51.135', 'restaurant_35.69_51.295', 'restaurant_35.705_51.295', 'restaurant_35.735_51.185', 'restaurant_35.745_51.045', 'restaurant_35.745_51.465', 'restaurant_35.74_51.2', 'restaurant_35.75_51.385', 'restaurant_35.765_51.075', 'restaurant_35.76_51.4', 'restaurant_35.785_51.24', 'restaurant_35.785_51.315', 'restaurant_35.805_51.345', 'restaurant_35.815_51.185', 'restaurant_35.815_51.32', 'restaurant_35.82_51.225', 'restaurant_35.865_51.045', 'restaurant_35.875_51.025', 'restaurant_35.875_51.275', 'restaurant_35.91_51.19', 'restaurant_35.945_51.17', 'restaurant_35.955_51.195', 'restaurant_35.95_51.315', 'restaurant_35.97_51.215', 'restaurant_35.98_51.05', 'restaurant_35.995_51.0', 'restaurant_36.0_51.085', 'restaurant_36.0_51.37', 'university_35.625_51.25', 'university_35.875_51.25', 'work_35.625_51.125', 'work_35.625_51.375', 'work_35.875_51.125', 'work_35.875_51.375']\n",
      "========================================\n",
      "Column: destination\n",
      "Unique values: ['gym', 'home', 'park', 'pool', 'restaurant', 'university', 'work']\n",
      "========================================\n",
      "Column: start_time\n",
      "Unique values: [360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 619, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 632, 633, 637, 638, 639, 640, 642, 643, 644, 647, 648, 649, 650, 651, 652, 654, 655, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1083, 1084, 1085, 1086, 1087, 1088, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1130, 1131, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1143, 1144, 1145, 1147, 1148, 1149, 1150, 1152, 1153, 1154, 1155, 1159, 1161, 1163, 1165, 1166, 1167, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1191, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1401, 1404, 1407, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1436, 1437]\n",
      "========================================\n",
      "Column: end_time\n",
      "Unique values: [365, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439]\n",
      "========================================\n",
      "Column: price\n",
      "Unique values: [10.0, 10.01, 10.02, 10.03, 10.04, 10.05, 10.06, 10.07, 10.08, 10.09, 10.1, 10.11, 10.12, 10.13, 10.14, 10.15, 10.16, 10.17, 10.18, 10.19, 10.2, 10.21, 10.22, 10.23, 10.24, 10.25, 10.26, 10.27, 10.28, 10.29, 10.3, 10.31, 10.32, 10.33, 10.34, 10.35, 10.36, 10.37, 10.38, 10.39, 10.4, 10.41, 10.42, 10.43, 10.44, 10.45, 10.46, 10.47, 10.48, 10.49, 10.5, 10.51, 10.52, 10.53, 10.54, 10.55, 10.56, 10.57, 10.58, 10.59, 10.6, 10.61, 10.62, 10.63, 10.64, 10.65, 10.66, 10.67, 10.68, 10.69, 10.7, 10.71, 10.72, 10.73, 10.74, 10.75, 10.76, 10.77, 10.78, 10.79, 10.8, 10.81, 10.82, 10.83, 10.84, 10.85, 10.86, 10.87, 10.88, 10.89, 10.9, 10.91, 10.92, 10.93, 10.94, 10.95, 10.96, 10.97, 10.98, 10.99, 11.0, 11.01, 11.02, 11.03, 11.04, 11.05, 11.06, 11.07, 11.08, 11.09, 11.1, 11.11, 11.12, 11.13, 11.14, 11.15, 11.16, 11.17, 11.18, 11.19, 11.2, 11.21, 11.22, 11.23, 11.24, 11.25, 11.26, 11.27, 11.28, 11.29, 11.3, 11.31, 11.32, 11.33, 11.34, 11.35, 11.36, 11.37, 11.38, 11.39, 11.4, 11.41, 11.42, 11.43, 11.44, 11.45, 11.46, 11.47, 11.48, 11.49, 11.5, 11.51, 11.52, 11.53, 11.54, 11.55, 11.56, 11.57, 11.58, 11.59, 11.6, 11.61, 11.62, 11.63, 11.64, 11.65, 11.66, 11.67, 11.68, 11.69, 11.7, 11.71, 11.72, 11.73, 11.74, 11.75, 11.76, 11.77, 11.78, 11.79, 11.8, 11.81, 11.82, 11.83, 11.84, 11.85, 11.86, 11.87, 11.88, 11.89, 11.9, 11.91, 11.92, 11.93, 11.94, 11.95, 11.96, 11.97, 11.98, 11.99, 12.0, 12.01, 12.02, 12.03, 12.04, 12.05, 12.06, 12.07, 12.08, 12.09, 12.1, 12.11, 12.12, 12.13, 12.14, 12.15, 12.16, 12.17, 12.18, 12.19, 12.2, 12.21, 12.22, 12.23, 12.24, 12.25, 12.26, 12.27, 12.28, 12.29, 12.3, 12.31, 12.32, 12.33, 12.34, 12.35, 12.36, 12.37, 12.38, 12.4, 12.41, 12.42, 12.43, 12.44, 12.45, 12.46, 12.47, 12.48, 12.49, 12.5, 12.51, 12.52, 12.53, 12.54, 12.55, 12.56, 12.57, 12.58, 12.59, 12.6, 12.61, 12.62, 12.63, 12.64, 12.65, 12.66, 12.67, 12.68, 12.69, 12.7, 12.71, 12.72, 12.73, 12.74, 12.75, 12.76, 12.77, 12.78, 12.79, 12.8, 12.81, 12.82, 12.83, 12.84, 12.85, 12.86, 12.87, 12.88, 12.89, 12.9, 12.91, 12.92, 12.93, 12.94, 12.95, 12.96, 12.97, 12.98, 12.99, 13.0, 13.01, 13.02, 13.03, 13.04, 13.05, 13.06, 13.07, 13.08, 13.09, 13.1, 13.11, 13.12, 13.13, 13.14, 13.15, 13.16, 13.17, 13.18, 13.19, 13.2, 13.21, 13.22, 13.23, 13.24, 13.25, 13.26, 13.27, 13.28, 13.29, 13.3, 13.31, 13.32, 13.33, 13.34, 13.35, 13.36, 13.37, 13.38, 13.39, 13.4, 13.41, 13.42, 13.43, 13.44, 13.45, 13.46, 13.47, 13.48, 13.49, 13.5, 13.51, 13.52, 13.53, 13.54, 13.55, 13.56, 13.57, 13.58, 13.59, 13.6, 13.61, 13.62, 13.63, 13.64, 13.65, 13.66, 13.67, 13.68, 13.69, 13.7, 13.71, 13.72, 13.73, 13.74, 13.75, 13.76, 13.77, 13.78, 13.79, 13.8, 13.81, 13.82, 13.83, 13.84, 13.85, 13.86, 13.87, 13.88, 13.89, 13.9, 13.91, 13.92, 13.93, 13.94, 13.95, 13.96, 13.97, 13.98, 13.99, 14.0, 14.01, 14.02, 14.03, 14.04, 14.05, 14.06, 14.07, 14.08, 14.09, 14.1, 14.11, 14.12, 14.13, 14.14, 14.15, 14.16, 14.17, 14.18, 14.19, 14.2, 14.21, 14.22, 14.23, 14.24, 14.25, 14.26, 14.27, 14.28, 14.29, 14.3, 14.31, 14.32, 14.33, 14.34, 14.35, 14.36, 14.37, 14.38, 14.39, 14.4, 14.41, 14.42, 14.43, 14.44, 14.45, 14.46, 14.47, 14.48, 14.49, 14.5, 14.51, 14.52, 14.53, 14.54, 14.55, 14.56, 14.57, 14.58, 14.59, 14.6, 14.61, 14.62, 14.63, 14.64, 14.65, 14.66, 14.67, 14.68, 14.69, 14.7, 14.71, 14.72, 14.73, 14.74, 14.75, 14.76, 14.77, 14.78, 14.79, 14.8, 14.81, 14.82, 14.83, 14.84, 14.85, 14.86, 14.87, 14.88, 14.89, 14.9, 14.91, 14.92, 14.93, 14.94, 14.95, 14.96, 14.97, 14.98, 14.99, 15.0, 15.01, 15.02, 15.03, 15.04, 15.05, 15.06, 15.07, 15.08, 15.09, 15.1, 15.11, 15.12, 15.13, 15.14, 15.15, 15.16, 15.17, 15.18, 15.19, 15.2, 15.21, 15.22, 15.23, 15.24, 15.25, 15.26, 15.27, 15.28, 15.29, 15.3, 15.31, 15.32, 15.33, 15.34, 15.35, 15.36, 15.37, 15.38, 15.39, 15.4, 15.41, 15.42, 15.43, 15.44, 15.45, 15.46, 15.47, 15.48, 15.49, 15.5, 15.51, 15.52, 15.53, 15.54, 15.55, 15.56, 15.57, 15.58, 15.59, 15.6, 15.61, 15.62, 15.63, 15.64, 15.65, 15.66, 15.67, 15.68, 15.69, 15.7, 15.71, 15.72, 15.73, 15.74, 15.75, 15.76, 15.77, 15.78, 15.79, 15.8, 15.81, 15.82, 15.83, 15.84, 15.85, 15.86, 15.87, 15.88, 15.89, 15.9, 15.91, 15.92, 15.93, 15.94, 15.95, 15.96, 15.97, 15.98, 15.99, 16.0, 16.01, 16.02, 16.03, 16.04, 16.05, 16.06, 16.07, 16.08, 16.09, 16.1, 16.11, 16.12, 16.13, 16.14, 16.15, 16.16, 16.17, 16.18, 16.19, 16.2, 16.21, 16.22, 16.23, 16.24, 16.25, 16.26, 16.27, 16.28, 16.29, 16.3, 16.31, 16.32, 16.33, 16.34, 16.35, 16.36, 16.37, 16.38, 16.39, 16.4, 16.41, 16.42, 16.43, 16.44, 16.45, 16.46, 16.47, 16.48, 16.49, 16.5, 16.51, 16.52, 16.53, 16.54, 16.55, 16.56, 16.57, 16.58, 16.59, 16.6, 16.61, 16.62, 16.63, 16.64, 16.65, 16.66, 16.67, 16.68, 16.69, 16.7, 16.71, 16.72, 16.73, 16.74, 16.75, 16.76, 16.77, 16.78, 16.79, 16.8, 16.81, 16.82, 16.83, 16.84, 16.85, 16.86, 16.87, 16.88, 16.89, 16.9, 16.91, 16.92, 16.93, 16.94, 16.95, 16.96, 16.97, 16.98, 16.99, 17.0, 17.01, 17.02, 17.03, 17.04, 17.05, 17.06, 17.07, 17.08, 17.09, 17.1, 17.11, 17.12, 17.13, 17.14, 17.15, 17.16, 17.17, 17.18, 17.19, 17.2, 17.21, 17.22, 17.23, 17.24, 17.25, 17.26, 17.27, 17.28, 17.29, 17.3, 17.31, 17.32, 17.33, 17.34, 17.35, 17.36, 17.37, 17.38, 17.39, 17.4, 17.41, 17.42, 17.43, 17.44, 17.45, 17.46, 17.47, 17.48, 17.49, 17.5, 17.51, 17.52, 17.53, 17.54, 17.55, 17.56, 17.57, 17.58, 17.59, 17.6, 17.61, 17.62, 17.63, 17.64, 17.65, 17.66, 17.67, 17.68, 17.69, 17.7, 17.71, 17.72, 17.73, 17.74, 17.75, 17.76, 17.77, 17.78, 17.79, 17.8, 17.81, 17.82, 17.83, 17.84, 17.85, 17.86, 17.87, 17.88, 17.89, 17.9, 17.91, 17.92, 17.93, 17.94, 17.95, 17.96, 17.97, 17.98, 17.99, 18.0, 18.01, 18.02, 18.03, 18.04, 18.05, 18.06, 18.07, 18.08, 18.09, 18.1, 18.11, 18.12, 18.13, 18.14, 18.15, 18.16, 18.17, 18.18, 18.19, 18.2, 18.21, 18.22, 18.23, 18.24, 18.25, 18.26, 18.27, 18.28, 18.29, 18.3, 18.31, 18.32, 18.33, 18.34, 18.35, 18.36, 18.37, 18.38, 18.39, 18.4, 18.41, 18.42, 18.43, 18.44, 18.45, 18.46, 18.47, 18.48, 18.49, 18.5, 18.51, 18.52, 18.53, 18.54, 18.55, 18.56, 18.57, 18.58, 18.59, 18.6, 18.61, 18.62, 18.63, 18.64, 18.65, 18.66, 18.67, 18.68, 18.69, 18.7, 18.71, 18.72, 18.73, 18.74, 18.75, 18.76, 18.77, 18.78, 18.79, 18.8, 18.81, 18.82, 18.83, 18.84, 18.85, 18.86, 18.87, 18.88, 18.89, 18.9, 18.91, 18.92, 18.93, 18.94, 18.95, 18.96, 18.97, 18.98, 18.99, 19.0, 19.01, 19.02, 19.03, 19.04, 19.05, 19.06, 19.07, 19.08, 19.09, 19.1, 19.11, 19.12, 19.13, 19.14, 19.15, 19.16, 19.17, 19.18, 19.19, 19.2, 19.21, 19.22, 19.23, 19.24, 19.25, 19.26, 19.27, 19.28, 19.29, 19.3, 19.31, 19.32, 19.33, 19.34, 19.35, 19.36, 19.37, 19.38, 19.39, 19.4, 19.41, 19.42, 19.43, 19.44, 19.45, 19.46, 19.47, 19.48, 19.49, 19.5, 19.51, 19.52, 19.53, 19.54, 19.55, 19.56, 19.57, 19.58, 19.59, 19.6, 19.61, 19.62, 19.63, 19.64, 19.65, 19.66, 19.67, 19.68, 19.69, 19.7, 19.71, 19.72, 19.73, 19.74, 19.75, 19.76, 19.77, 19.78, 19.79, 19.8, 19.81, 19.82, 19.83, 19.84, 19.85, 19.86, 19.87, 19.88, 19.89, 19.9, 19.91, 19.92, 19.93, 19.94, 19.95, 19.96, 19.97, 19.98, 19.99, 20.0, 20.01, 20.02, 20.03, 20.04, 20.05, 20.06, 20.07, 20.08, 20.09, 20.1, 20.11, 20.12, 20.13, 20.14, 20.15, 20.16, 20.17, 20.18, 20.19, 20.2, 20.21, 20.22, 20.23, 20.24, 20.25, 20.26, 20.27, 20.28, 20.29, 20.3, 20.31, 20.33, 20.34, 20.35, 20.36, 20.37, 20.38, 20.39, 20.4, 20.41, 20.42, 20.43, 20.44, 20.45, 20.46, 20.47, 20.48, 20.49, 20.5, 20.51, 20.52, 20.53, 20.54, 20.55, 20.56, 20.57, 20.58, 20.59, 20.6, 20.61, 20.62, 20.63, 20.64, 20.65, 20.66, 20.67, 20.68, 20.69, 20.7, 20.71, 20.72, 20.73, 20.74, 20.75, 20.76, 20.77, 20.78, 20.79, 20.8, 20.81, 20.82, 20.83, 20.84, 20.85, 20.86, 20.87, 20.88, 20.89, 20.9, 20.91, 20.92, 20.93, 20.94, 20.95, 20.96, 20.97, 20.98, 20.99, 21.0, 21.01, 21.02, 21.03, 21.04, 21.05, 21.06, 21.07, 21.08, 21.09, 21.1, 21.11, 21.12, 21.13, 21.14, 21.15, 21.16, 21.17, 21.18, 21.19, 21.2, 21.21, 21.22, 21.23, 21.24, 21.25, 21.26, 21.27, 21.28, 21.29, 21.3, 21.31, 21.32, 21.33, 21.34, 21.35, 21.36, 21.37, 21.38, 21.39, 21.4, 21.41, 21.42, 21.43, 21.44, 21.45, 21.46, 21.47, 21.48, 21.49, 21.5, 21.51, 21.52, 21.53, 21.54, 21.55, 21.56, 21.57, 21.58, 21.59, 21.6, 21.61, 21.62, 21.63, 21.64, 21.65, 21.66, 21.67, 21.68, 21.69, 21.7, 21.71, 21.72, 21.73, 21.74, 21.75, 21.76, 21.77, 21.78, 21.79, 21.8, 21.81, 21.82, 21.83, 21.84, 21.85, 21.86, 21.87, 21.88, 21.89, 21.9, 21.91, 21.92, 21.93, 21.94, 21.95, 21.96, 21.97, 21.98, 21.99, 22.0, 22.01, 22.02, 22.03, 22.04, 22.05, 22.06, 22.07, 22.08, 22.09, 22.1, 22.11, 22.12, 22.13, 22.14, 22.15, 22.16, 22.17, 22.18, 22.19, 22.2, 22.21, 22.22, 22.23, 22.24, 22.25, 22.26, 22.27, 22.28, 22.29, 22.3, 22.31, 22.32, 22.33, 22.34, 22.35, 22.36, 22.37, 22.38, 22.39, 22.4, 22.41, 22.42, 22.43, 22.44, 22.45, 22.46, 22.47, 22.48, 22.49, 22.5, 22.51, 22.52, 22.53, 22.54, 22.55, 22.56, 22.57, 22.58, 22.59, 22.6, 22.61, 22.62, 22.63, 22.64, 22.65, 22.66, 22.67, 22.68, 22.69, 22.7, 22.71, 22.72, 22.73, 22.74, 22.75, 22.76, 22.77, 22.78, 22.79, 22.8, 22.81, 22.82, 22.83, 22.84, 22.85, 22.86, 22.87, 22.88, 22.89, 22.9, 22.91, 22.92, 22.93, 22.94, 22.95, 22.96, 22.97, 22.98, 22.99, 23.0, 23.01, 23.02, 23.03, 23.04, 23.05, 23.06, 23.07, 23.08, 23.09, 23.1, 23.11, 23.12, 23.13, 23.14, 23.15, 23.16, 23.17, 23.18, 23.19, 23.2, 23.21, 23.22, 23.23, 23.24, 23.25, 23.26, 23.27, 23.28, 23.29, 23.3, 23.31, 23.32, 23.33, 23.34, 23.35, 23.36, 23.37, 23.38, 23.39, 23.4, 23.41, 23.42, 23.43, 23.44, 23.45, 23.46, 23.47, 23.48, 23.49, 23.5, 23.51, 23.52, 23.53, 23.54, 23.55, 23.56, 23.57, 23.58, 23.59, 23.6, 23.61, 23.62, 23.63, 23.64, 23.65, 23.66, 23.67, 23.68, 23.69, 23.7, 23.71, 23.72, 23.73, 23.74, 23.75, 23.76, 23.77, 23.78, 23.79, 23.8, 23.81, 23.82, 23.83, 23.84, 23.85, 23.86, 23.87, 23.88, 23.89, 23.9, 23.91, 23.92, 23.93, 23.94, 23.95, 23.96, 23.97, 23.98, 23.99, 24.0, 24.01, 24.02, 24.03, 24.04, 24.05, 24.06, 24.07, 24.08, 24.09, 24.1, 24.11, 24.12, 24.13, 24.14, 24.15, 24.16, 24.17, 24.18, 24.19, 24.2, 24.21, 24.22, 24.23, 24.24, 24.25, 24.26, 24.27, 24.28, 24.29, 24.3, 24.31, 24.32, 24.33, 24.34, 24.35, 24.36, 24.37, 24.38, 24.39, 24.4, 24.41, 24.42, 24.43, 24.44, 24.45, 24.46, 24.47, 24.48, 24.49, 24.5, 24.51, 24.52, 24.53, 24.54, 24.55, 24.56, 24.57, 24.58, 24.59, 24.6, 24.61, 24.62, 24.63, 24.64, 24.65, 24.66, 24.67, 24.68, 24.69, 24.7, 24.71, 24.72, 24.73, 24.74, 24.75, 24.76, 24.77, 24.78, 24.79, 24.8, 24.81, 24.82, 24.83, 24.84, 24.85, 24.86, 24.87, 24.88, 24.89, 24.9, 24.91, 24.92, 24.93, 24.94, 24.95, 24.96, 24.97, 24.98, 24.99, 25.0, 25.01, 25.02, 25.03, 25.04, 25.05, 25.06, 25.07, 25.08, 25.09, 25.1, 25.11, 25.12, 25.13, 25.14, 25.15, 25.16, 25.17, 25.18, 25.19, 25.2, 25.21, 25.22, 25.23, 25.24, 25.25, 25.26, 25.27, 25.28, 25.29, 25.3, 25.31, 25.32, 25.33, 25.34, 25.35, 25.36, 25.37, 25.38, 25.39, 25.4, 25.41, 25.42, 25.43, 25.44, 25.45, 25.46, 25.47, 25.48, 25.49, 25.5, 25.51, 25.52, 25.53, 25.54, 25.55, 25.56, 25.57, 25.58, 25.59, 25.6, 25.61, 25.62, 25.63, 25.64, 25.65, 25.66, 25.67, 25.68, 25.69, 25.7, 25.71, 25.72, 25.73, 25.74, 25.75, 25.76, 25.77, 25.78, 25.79, 25.8, 25.81, 25.82, 25.83, 25.85, 25.86, 25.87, 25.88, 25.89, 25.9, 25.91, 25.92, 25.93, 25.94, 25.95, 25.96, 25.97, 25.98, 25.99, 26.0, 26.01, 26.02, 26.03, 26.04, 26.05, 26.06, 26.07, 26.08, 26.09, 26.1, 26.11, 26.12, 26.13, 26.14, 26.15, 26.16, 26.17, 26.18, 26.19, 26.2, 26.21, 26.22, 26.23, 26.24, 26.25, 26.26, 26.27, 26.28, 26.29, 26.3, 26.31, 26.32, 26.33, 26.34, 26.35, 26.36, 26.37, 26.38, 26.39, 26.4, 26.41, 26.42, 26.43, 26.44, 26.45, 26.46, 26.47, 26.48, 26.49, 26.5, 26.51, 26.52, 26.53, 26.54, 26.55, 26.56, 26.57, 26.58, 26.59, 26.6, 26.61, 26.62, 26.63, 26.64, 26.65, 26.66, 26.67, 26.68, 26.69, 26.7, 26.71, 26.72, 26.73, 26.74, 26.75, 26.76, 26.77, 26.78, 26.79, 26.8, 26.81, 26.82, 26.83, 26.84, 26.85, 26.86, 26.87, 26.88, 26.89, 26.9, 26.91, 26.92, 26.93, 26.94, 26.95, 26.96, 26.97, 26.98, 26.99, 27.0, 27.01, 27.02, 27.03, 27.04, 27.05, 27.06, 27.07, 27.08, 27.1, 27.11, 27.12, 27.13, 27.14, 27.15, 27.16, 27.17, 27.18, 27.19, 27.2, 27.21, 27.22, 27.23, 27.24, 27.25, 27.26, 27.27, 27.28, 27.29, 27.3, 27.31, 27.32, 27.33, 27.34, 27.35, 27.36, 27.37, 27.38, 27.39, 27.4, 27.41, 27.42, 27.43, 27.44, 27.45, 27.46, 27.47, 27.48, 27.49, 27.5, 27.51, 27.52, 27.53, 27.54, 27.55, 27.56, 27.57, 27.58, 27.59, 27.6, 27.61, 27.62, 27.63, 27.64, 27.65, 27.66, 27.67, 27.68, 27.69, 27.7, 27.71, 27.72, 27.73, 27.74, 27.75, 27.76, 27.77, 27.78, 27.79, 27.8, 27.81, 27.82, 27.83, 27.84, 27.85, 27.86, 27.87, 27.88, 27.89, 27.9, 27.91, 27.92, 27.93, 27.94, 27.95, 27.96, 27.97, 27.98, 27.99, 28.0, 28.01, 28.02, 28.03, 28.04, 28.05, 28.06, 28.07, 28.08, 28.09, 28.1, 28.11, 28.12, 28.13, 28.14, 28.15, 28.16, 28.17, 28.18, 28.19, 28.2, 28.21, 28.22, 28.23, 28.25, 28.26, 28.27, 28.28, 28.29, 28.3, 28.31, 28.32, 28.33, 28.34, 28.35, 28.36, 28.37, 28.38, 28.39, 28.4, 28.41, 28.42, 28.43, 28.44, 28.45, 28.46, 28.47, 28.48, 28.49, 28.5, 28.51, 28.52, 28.53, 28.54, 28.55, 28.56, 28.57, 28.58, 28.59, 28.6, 28.61, 28.62, 28.63, 28.64, 28.65, 28.67, 28.68, 28.69, 28.7, 28.71, 28.72, 28.73, 28.74, 28.75, 28.76, 28.77, 28.78, 28.79, 28.8, 28.81, 28.82, 28.83, 28.84, 28.85, 28.86, 28.87, 28.88, 28.89, 28.9, 28.91, 28.92, 28.93, 28.94, 28.95, 28.96, 28.97, 28.98, 28.99, 29.0, 29.01, 29.02, 29.03, 29.04, 29.05, 29.06, 29.07, 29.08, 29.09, 29.1, 29.12, 29.13, 29.14, 29.15, 29.16, 29.17, 29.18, 29.19, 29.2, 29.21, 29.22, 29.23, 29.24, 29.25, 29.26, 29.27, 29.28, 29.29, 29.3, 29.31, 29.32, 29.33, 29.34, 29.35, 29.36, 29.37, 29.38, 29.39, 29.4, 29.41, 29.42, 29.43, 29.44, 29.45, 29.46, 29.47, 29.48, 29.49, 29.5, 29.51, 29.52, 29.53, 29.54, 29.55, 29.56, 29.57, 29.58, 29.59, 29.6, 29.61, 29.62, 29.63, 29.64, 29.65, 29.66, 29.67, 29.68, 29.69, 29.7, 29.71, 29.72, 29.73, 29.74, 29.75, 29.76, 29.77, 29.78, 29.79, 29.8, 29.81, 29.82, 29.83, 29.84, 29.85, 29.86, 29.87, 29.88, 29.89, 29.9, 29.91, 29.92, 29.93, 29.94, 29.95, 29.96, 29.97, 29.98, 29.99, 30.0, 30.01, 30.02, 30.03, 30.04, 30.05, 30.06, 30.07, 30.08, 30.09, 30.1, 30.11, 30.12, 30.13, 30.14, 30.15, 30.16, 30.17, 30.18, 30.19, 30.2, 30.21, 30.22, 30.23, 30.24, 30.25, 30.26, 30.27, 30.28, 30.29, 30.3, 30.31, 30.32, 30.33, 30.34, 30.35, 30.36, 30.37, 30.38, 30.39, 30.4, 30.41, 30.42, 30.43, 30.44, 30.45, 30.46, 30.47, 30.48, 30.49, 30.5, 30.51, 30.52, 30.53, 30.54, 30.55, 30.56, 30.57, 30.58, 30.59, 30.61, 30.62, 30.63, 30.64, 30.65, 30.66, 30.67, 30.68, 30.69, 30.7, 30.71, 30.72, 30.73, 30.74, 30.75, 30.76, 30.77, 30.78, 30.79, 30.8, 30.81, 30.82, 30.83, 30.84, 30.85, 30.86, 30.87, 30.88, 30.89, 30.9, 30.92, 30.93, 30.94, 30.95, 30.96, 30.97, 30.98, 30.99, 31.0, 31.01, 31.02, 31.04, 31.05, 31.06, 31.07, 31.08, 31.09, 31.1, 31.11, 31.12, 31.13, 31.14, 31.15, 31.16, 31.17, 31.18, 31.19, 31.2, 31.21, 31.22, 31.23, 31.24, 31.25, 31.26, 31.27, 31.28, 31.29, 31.3, 31.31, 31.32, 31.33, 31.34, 31.35, 31.36, 31.37, 31.38, 31.39, 31.4, 31.41, 31.42, 31.43, 31.45, 31.46, 31.47, 31.48, 31.49, 31.5, 31.51, 31.52, 31.53, 31.54, 31.55, 31.56, 31.57, 31.58, 31.59, 31.6, 31.61, 31.62, 31.63, 31.64, 31.65, 31.66, 31.67, 31.68, 31.69, 31.7, 31.71, 31.72, 31.73, 31.74, 31.75, 31.76, 31.77, 31.78, 31.79, 31.8, 31.81, 31.82, 31.83, 31.84, 31.85, 31.86, 31.87, 31.88, 31.89, 31.9, 31.91, 31.92, 31.93, 31.94, 31.95, 31.96, 31.97, 31.98, 31.99, 32.0, 32.01, 32.02, 32.04, 32.05, 32.06, 32.07, 32.08, 32.09, 32.1, 32.11, 32.12, 32.13, 32.14, 32.15, 32.16, 32.17, 32.18, 32.19, 32.2, 32.21, 32.22, 32.23, 32.24, 32.25, 32.26, 32.27, 32.28, 32.29, 32.3, 32.31, 32.32, 32.33, 32.34, 32.35, 32.36, 32.37, 32.38, 32.39, 32.4, 32.41, 32.42, 32.43, 32.44, 32.45, 32.46, 32.47, 32.48, 32.49, 32.5, 32.51, 32.52, 32.53, 32.54, 32.55, 32.56, 32.57, 32.58, 32.59, 32.6, 32.61, 32.62, 32.63, 32.64, 32.65, 32.66, 32.67, 32.68, 32.69, 32.7, 32.71, 32.72, 32.73, 32.74, 32.75, 32.76, 32.77, 32.78, 32.79, 32.8, 32.81, 32.82, 32.83, 32.84, 32.85, 32.86, 32.87, 32.89, 32.91, 32.92, 32.94, 32.95, 32.96, 32.97, 32.98, 32.99, 33.0, 33.01, 33.02, 33.03, 33.04, 33.05, 33.06, 33.09, 33.1, 33.11, 33.12, 33.13, 33.14, 33.15, 33.16, 33.17, 33.18, 33.19, 33.2, 33.21, 33.22, 33.23, 33.24, 33.25, 33.26, 33.27, 33.28, 33.29, 33.3, 33.31, 33.32, 33.33, 33.34, 33.35, 33.36, 33.37, 33.38, 33.41, 33.42, 33.43, 33.44, 33.45, 33.46, 33.48, 33.5, 33.51, 33.52, 33.53, 33.54, 33.55, 33.56, 33.57, 33.58, 33.59, 33.6, 33.61, 33.62, 33.63, 33.64, 33.65, 33.66, 33.67, 33.68, 33.69, 33.7, 33.71, 33.72, 33.73, 33.75, 33.76, 33.77, 33.78, 33.79, 33.8, 33.81, 33.82, 33.83, 33.84, 33.85, 33.86, 33.87, 33.88, 33.9, 33.91, 33.92, 33.93, 33.94, 33.95, 33.96, 33.98, 33.99, 34.0, 34.01, 34.02, 34.03, 34.05, 34.06, 34.07, 34.08, 34.09, 34.1, 34.11, 34.12, 34.13, 34.14, 34.15, 34.16, 34.17, 34.18, 34.19, 34.2, 34.21, 34.23, 34.24, 34.25, 34.26, 34.27, 34.28, 34.29, 34.31, 34.32, 34.33, 34.34, 34.35, 34.36, 34.37, 34.38, 34.39, 34.4, 34.41, 34.42, 34.43, 34.44, 34.45, 34.46, 34.47, 34.48, 34.49, 34.51, 34.53, 34.54, 34.55, 34.56, 34.57, 34.58, 34.59, 34.6, 34.62, 34.63, 34.64, 34.65, 34.66, 34.67, 34.68, 34.69, 34.7, 34.71, 34.72, 34.73, 34.74, 34.75, 34.76, 34.77, 34.78, 34.79, 34.8, 34.81, 34.82, 34.83, 34.84, 34.85, 34.86, 34.87, 34.88, 34.89, 34.9, 34.91, 34.92, 34.94, 34.95, 34.96, 34.97, 34.98, 34.99, 35.02, 35.03, 35.05, 35.06, 35.07, 35.08, 35.09, 35.1, 35.12, 35.13, 35.14, 35.15, 35.16, 35.17, 35.18, 35.19, 35.2, 35.21, 35.23, 35.24, 35.25, 35.26, 35.27, 35.28, 35.29, 35.3, 35.31, 35.32, 35.33, 35.34, 35.36, 35.37, 35.38, 35.39, 35.4, 35.41, 35.42, 35.43, 35.44, 35.45, 35.46, 35.47, 35.48, 35.49, 35.51, 35.52, 35.53, 35.54, 35.55, 35.56, 35.58, 35.59, 35.6, 35.61, 35.63, 35.64, 35.65, 35.66, 35.67, 35.68, 35.69, 35.7, 35.72, 35.73, 35.74, 35.75, 35.76, 35.77, 35.78, 35.8, 35.81, 35.84, 35.85, 35.87, 35.88, 35.89, 35.9, 35.91, 35.93, 35.94, 35.95, 35.96, 35.97, 35.98, 35.99, 36.0, 36.01, 36.02, 36.03, 36.05, 36.06, 36.09, 36.1, 36.11, 36.12, 36.13, 36.14, 36.17, 36.19, 36.2, 36.21, 36.22, 36.23, 36.24, 36.25, 36.26, 36.27, 36.28, 36.29, 36.3, 36.31, 36.33, 36.34, 36.35, 36.36, 36.37, 36.38, 36.39, 36.4, 36.41, 36.42, 36.43, 36.44, 36.46, 36.47, 36.48, 36.5, 36.51, 36.52, 36.53, 36.54, 36.56, 36.58, 36.59, 36.6, 36.61, 36.62, 36.63, 36.64, 36.65, 36.66, 36.67, 36.69, 36.7, 36.71, 36.72, 36.73, 36.74, 36.75, 36.76, 36.77, 36.78, 36.79, 36.8, 36.81, 36.82, 36.83, 36.84, 36.85, 36.87, 36.9, 36.91, 36.94, 36.96, 36.97, 36.98, 36.99, 37.0, 37.01, 37.02, 37.03, 37.04, 37.05, 37.06, 37.07, 37.08, 37.11, 37.13, 37.14, 37.15, 37.16, 37.17, 37.18, 37.19, 37.2, 37.21, 37.22, 37.23, 37.24, 37.25, 37.26, 37.27, 37.28, 37.29, 37.3, 37.31, 37.32, 37.33, 37.34, 37.37, 37.38, 37.39, 37.4, 37.41, 37.42, 37.43, 37.44, 37.45, 37.46, 37.47, 37.48, 37.49, 37.5, 37.51, 37.53, 37.54, 37.55, 37.56, 37.57, 37.58, 37.59, 37.6, 37.61, 37.62, 37.63, 37.66, 37.67, 37.68, 37.69, 37.7, 37.71, 37.72, 37.73, 37.74, 37.75, 37.76, 37.77, 37.78, 37.79, 37.8, 37.81, 37.82, 37.83, 37.85, 37.86, 37.87, 37.89, 37.9, 37.91, 37.93, 37.94, 37.96, 37.97, 37.98, 37.99, 38.0, 38.01, 38.02, 38.03, 38.04, 38.05, 38.06, 38.07, 38.08, 38.09, 38.1, 38.11, 38.12, 38.13, 38.14, 38.18, 38.2, 38.21, 38.22, 38.23, 38.24, 38.25, 38.27, 38.29, 38.3, 38.31, 38.32, 38.33, 38.35, 38.38, 38.39, 38.4, 38.41, 38.43, 38.44, 38.47, 38.48, 38.5, 38.51, 38.53, 38.54, 38.55, 38.56, 38.57, 38.58, 38.59, 38.6, 38.61, 38.62, 38.63, 38.64, 38.65, 38.66, 38.68, 38.69, 38.7, 38.71, 38.72, 38.74, 38.75, 38.76, 38.77, 38.79, 38.8, 38.81, 38.82, 38.83, 38.84, 38.85, 38.88, 38.89, 38.9, 38.91, 38.93, 38.94, 38.95, 38.96, 38.97, 38.98, 38.99, 39.0, 39.01, 39.02, 39.03, 39.05, 39.07, 39.08, 39.09, 39.1, 39.11, 39.12, 39.14, 39.18, 39.19, 39.21, 39.22, 39.24, 39.26, 39.27, 39.28, 39.3, 39.31, 39.33, 39.34, 39.35, 39.36, 39.37, 39.38, 39.39, 39.4, 39.42, 39.43, 39.44, 39.45, 39.46, 39.47, 39.48, 39.49, 39.51, 39.52, 39.53, 39.55, 39.56, 39.57, 39.58, 39.59, 39.6, 39.61, 39.63, 39.64, 39.65, 39.66, 39.67, 39.68, 39.69, 39.7, 39.71, 39.72, 39.73, 39.74, 39.76, 39.79, 39.8, 39.81, 39.82, 39.83, 39.84, 39.86, 39.88, 39.89, 39.91, 39.94, 39.96, 39.97, 39.98, 40.0, 40.01, 40.02, 40.04, 40.05, 40.06, 40.07, 40.08, 40.09, 40.1, 40.12, 40.13, 40.14, 40.16, 40.17, 40.19, 40.21, 40.24, 40.26, 40.27, 40.28, 40.3, 40.31, 40.32, 40.33, 40.34, 40.35, 40.36, 40.37, 40.38, 40.43, 40.46, 40.47, 40.48, 40.49, 40.52, 40.53, 40.55, 40.57, 40.58, 40.59, 40.61, 40.62, 40.63, 40.65, 40.66, 40.67, 40.71, 40.72, 40.74, 40.76, 40.77, 40.79, 40.8, 40.82, 40.84, 40.88, 40.89, 40.92, 40.93, 40.94, 40.95, 40.96, 40.97, 41.0, 41.01, 41.02, 41.03, 41.08, 41.09, 41.1, 41.11, 41.12, 41.13, 41.14, 41.15, 41.17, 41.18, 41.2, 41.21, 41.22, 41.23, 41.28, 41.31, 41.32, 41.33, 41.34, 41.36, 41.37, 41.4, 41.42, 41.43, 41.44, 41.46, 41.49, 41.5, 41.51, 41.53, 41.61, 41.62, 41.63, 41.64, 41.65, 41.67, 41.71, 41.72, 41.73, 41.74, 41.75, 41.82, 41.84, 41.85, 41.9, 41.91, 41.93, 41.98, 42.0, 42.01, 42.02, 42.03, 42.04, 42.05, 42.06, 42.08, 42.09, 42.16, 42.18, 42.22, 42.23, 42.27, 42.29, 42.31, 42.32, 42.33, 42.36, 42.4, 42.42, 42.43, 42.51, 42.52, 42.54, 42.56, 42.59, 42.65, 42.66, 42.67, 42.7, 42.72, 42.74, 42.76, 42.77, 42.78, 42.82, 42.87, 42.89, 42.94, 42.98, 42.99, 43.0, 43.01, 43.03, 43.09, 43.12, 43.13, 43.14, 43.18, 43.19, 43.22, 43.23, 43.24, 43.26, 43.3, 43.31, 43.34, 43.35, 43.41, 43.43, 43.45, 43.46, 43.47, 43.48, 43.49, 43.52, 43.54, 43.56, 43.57, 43.61, 43.66, 43.67, 43.68, 43.76, 43.79, 43.82, 43.83, 43.86, 43.87, 43.89, 43.9, 43.95, 43.99, 44.0, 44.02, 44.03, 44.04, 44.05, 44.08, 44.11, 44.15, 44.19, 44.21, 44.25, 44.27, 44.32, 44.35, 44.38, 44.45, 44.51, 44.53, 44.54, 44.55, 44.57, 44.6, 44.62, 44.64, 44.66, 44.69, 44.73, 44.76, 44.77, 44.78, 44.81, 44.83, 44.85, 44.92, 45.05, 45.14, 45.2, 45.21, 45.22, 45.25, 45.29, 45.31, 45.34, 45.37, 45.41, 45.43, 45.45, 45.5, 45.53, 45.58, 45.6, 45.61, 45.63, 45.65, 45.71, 45.75, 45.76, 45.77, 45.78, 45.82, 45.86, 45.87, 45.92, 46.01, 46.05, 46.07, 46.14, 46.24, 46.25, 46.32, 46.33, 46.35, 46.37, 46.41, 46.49, 46.5, 46.57, 46.59, 46.6, 46.67, 46.73, 46.76, 46.79, 46.84, 46.89, 46.91, 47.02, 47.08, 47.1, 47.17, 47.23, 47.33, 47.34, 47.37, 47.42, 47.43, 47.44, 47.47, 47.48, 47.49, 47.55, 47.62, 47.63, 47.7, 47.85, 47.9, 47.93, 47.94, 47.96, 47.97, 48.06, 48.11, 48.12, 48.13, 48.14, 48.15, 48.17, 48.2, 48.22, 48.3, 48.36, 48.39, 48.4, 48.42, 48.45, 48.48, 48.52, 48.53, 48.59, 48.6, 48.62, 48.65, 48.68, 48.74, 48.76, 48.8, 48.88, 48.93, 49.04, 49.12, 49.14, 49.26, 49.3, 49.35, 49.36, 49.47, 49.51, 49.53, 49.57, 49.61, 49.63, 49.65, 49.66, 49.74, 49.76, 49.83, 49.85, 49.88, 49.99, 50.06, 50.07, 50.2, 50.29, 50.3, 50.76, 50.77, 50.88, 50.92, 50.96, 51.0, 51.08, 51.18, 51.31, 51.32, 51.38, 51.44, 51.72, 51.98, 52.12, 52.28, 52.29, 52.58, 52.9, 53.06, 53.76, 54.05, 54.35, 54.46, 55.0, 55.65, 56.32, 56.48, 56.53, 56.66, 56.71, 56.85, 58.01, 58.57, 59.24, 59.79, 59.82, 60.29, 60.3, 60.82, 62.6, 63.29, 65.3, 65.8, 66.81, 67.93, 69.9, 69.97, 70.82, 73.01, 77.97]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# print out the unique values for each column\n",
    "for col in df.columns:\n",
    "    print(f\"Column: {col}\\nUnique values: {sorted(df[col].unique())}\\n========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Column Head and Data Type:\n",
      "========================================\n",
      "Column: user_id\n",
      "Data Type: int64\n",
      "----------------------------------------\n",
      "Column: Day\n",
      "Data Type: int64\n",
      "----------------------------------------\n",
      "Column: origin\n",
      "Data Type: object\n",
      "----------------------------------------\n",
      "Column: destination\n",
      "Data Type: object\n",
      "----------------------------------------\n",
      "Column: start_time\n",
      "Data Type: int64\n",
      "----------------------------------------\n",
      "Column: end_time\n",
      "Data Type: int64\n",
      "----------------------------------------\n",
      "Column: price\n",
      "Data Type: float64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# print out the data type of each column\n",
    "print(\"DataFrame Column Head and Data Type:\\n========================================\")\n",
    "for col in df.columns:\n",
    "    print(f\"Column: {col}\\nData Type: {df[col].dtype}\\n----------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your features and how you extracted them, you may need to use some encodings for your data. For example, if you have different classes as names (`str` data type. E.g. \"gym\") you need to make it a numeric value in order to feed it into your neural network. You can use `sklearn`'s functions (such as `LabelEncoder`, `OneHotEncoder`, `StandardScaler`, etc.) to do these kind of stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Finalize the data (do all preprocessing needed)\n",
    "train_X_enc = train_X.copy()\n",
    "test_X_enc = test_X.copy()\n",
    "\n",
    "train_y_enc = train_y.copy()\n",
    "test_y_enc = test_y.copy()\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "train_X_enc[\"origin\"] = label_enc.fit_transform(train_X[\"origin\"])\n",
    "test_X_enc[\"origin\"] = label_enc.transform(test_X[\"origin\"])\n",
    "\n",
    "train_y_enc[\"destination\"] = label_enc.fit_transform(train_y[\"destination\"])\n",
    "test_y_enc[\"destination\"] = label_enc.transform(test_y[\"destination\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_X_enc = pd.DataFrame(scaler.fit_transform(train_X_enc), columns=train_X_enc.columns)\n",
    "test_X_enc = pd.DataFrame(scaler.transform(test_X_enc), columns=test_X_enc.columns)\n",
    "\n",
    "train_X_enc, val_X_enc, train_y_enc, val_y_enc = train_test_split(train_X_enc, train_y_enc, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `train_dataset` and its loader, also create `test_dataset` and its loader. You should also create `val_dataset` and its loader if you want to use validation set. You may need to implement a custom `torch.Dataset` class for your ease. Your loaders should be able to load data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class SparseDataset(Dataset):\n",
    "    def __init__(self, X, y, device=\"cpu\"):\n",
    "        self.X = torch.tensor(X.to_numpy(), dtype=torch.float32, device=device)\n",
    "        self.y = torch.tensor(y.to_numpy(), dtype=torch.int64, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = SparseDataset(train_X_enc, train_y_enc[\"destination\"])\n",
    "val_dataset = SparseDataset(val_X_enc, val_y_enc[\"destination\"])\n",
    "test_dataset = SparseDataset(test_X_enc, test_y_enc[\"destination\"])\n",
    "\n",
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you should implement your neural network model. You should use `pytorch`. **Note** that you should plot the loss function of your model during the training phase. (on both training and validation sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the train_model function\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss}, Val Loss: {val_loss}\")\n",
    "\n",
    "    # Plot training and validation losses\n",
    "    plt.plot(range(1, epochs+1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, epochs+1), val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Losses')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Implement the MLP class with your choice of architecture\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, output_dim)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "\n",
    "# Define Model, Loss, Optimizer\n",
    "model = MLP(train_X_enc.shape[1], train_y_enc[\"destination\"].nunique())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.9317708338453936, Val Loss: 0.6303542955413929\n",
      "Epoch 2/100, Train Loss: 0.5498450489166753, Val Loss: 0.49679248988479335\n",
      "Epoch 3/100, Train Loss: 0.44533967169758015, Val Loss: 0.47112369380019775\n",
      "Epoch 4/100, Train Loss: 0.4059729959182998, Val Loss: 0.428341947916184\n",
      "Epoch 5/100, Train Loss: 0.379721277064025, Val Loss: 0.38775132690478975\n",
      "Epoch 6/100, Train Loss: 0.36961195964124227, Val Loss: 0.3675189163162166\n",
      "Epoch 7/100, Train Loss: 0.3685799924459421, Val Loss: 0.35937731605200146\n",
      "Epoch 8/100, Train Loss: 0.3451632235562814, Val Loss: 0.3514723230746429\n",
      "Epoch 9/100, Train Loss: 0.34754302579936736, Val Loss: 0.335076617048528\n",
      "Epoch 10/100, Train Loss: 0.3368078296343541, Val Loss: 0.3570153551917833\n",
      "Epoch 11/100, Train Loss: 0.3332102360349432, Val Loss: 0.3365499091896954\n",
      "Epoch 12/100, Train Loss: 0.3335693876935443, Val Loss: 0.3401345464877865\n",
      "Epoch 13/100, Train Loss: 0.32979656640710664, Val Loss: 0.3442222217978223\n",
      "Epoch 14/100, Train Loss: 0.3285194202155113, Val Loss: 0.3629122423310848\n",
      "Epoch 15/100, Train Loss: 0.33040513324836923, Val Loss: 0.3800601210816763\n",
      "Epoch 16/100, Train Loss: 0.32247758713932906, Val Loss: 0.33916154216481237\n",
      "Epoch 17/100, Train Loss: 0.3209208681108058, Val Loss: 0.34774232545008954\n",
      "Epoch 18/100, Train Loss: 0.3231443956468452, Val Loss: 0.32918236821384755\n",
      "Epoch 19/100, Train Loss: 0.3168462607545048, Val Loss: 0.3542719007399586\n",
      "Epoch 20/100, Train Loss: 0.3161669642292157, Val Loss: 0.329831732332988\n",
      "Epoch 21/100, Train Loss: 0.31518721402457456, Val Loss: 0.3547927456436703\n",
      "Epoch 22/100, Train Loss: 0.3119106501951612, Val Loss: 0.3288196920934536\n",
      "Epoch 23/100, Train Loss: 0.3162325862320234, Val Loss: 0.33211465657303885\n",
      "Epoch 24/100, Train Loss: 0.30963720125678346, Val Loss: 0.3727782093408738\n",
      "Epoch 25/100, Train Loss: 0.31245209722313544, Val Loss: 0.3343895945276741\n",
      "Epoch 26/100, Train Loss: 0.3056324945530489, Val Loss: 0.33041157003540766\n",
      "Epoch 27/100, Train Loss: 0.30823831237741295, Val Loss: 0.33964121727587016\n",
      "Epoch 28/100, Train Loss: 0.30335482288127397, Val Loss: 0.33987623363708447\n",
      "Epoch 29/100, Train Loss: 0.3027527248167917, Val Loss: 0.3294830374682602\n",
      "Epoch 30/100, Train Loss: 0.3013728790603689, Val Loss: 0.32517026072907823\n",
      "Epoch 31/100, Train Loss: 0.299967511218221, Val Loss: 0.3348231415478313\n",
      "Epoch 32/100, Train Loss: 0.2967745244896383, Val Loss: 0.3357757817841\n",
      "Epoch 33/100, Train Loss: 0.3008727794556454, Val Loss: 0.3298128700133793\n",
      "Epoch 34/100, Train Loss: 0.30502956925932423, Val Loss: 0.31454902978432314\n",
      "Epoch 35/100, Train Loss: 0.2902085738862791, Val Loss: 0.3285753488640018\n",
      "Epoch 36/100, Train Loss: 0.29535370739270683, Val Loss: 0.31858258137738715\n",
      "Epoch 37/100, Train Loss: 0.28921838406888756, Val Loss: 0.3253707271478149\n",
      "Epoch 38/100, Train Loss: 0.2901949765347656, Val Loss: 0.35773503523662575\n",
      "Epoch 39/100, Train Loss: 0.29946915535680035, Val Loss: 0.315443998717639\n",
      "Epoch 40/100, Train Loss: 0.28954093884411436, Val Loss: 0.31550571696729784\n",
      "Epoch 41/100, Train Loss: 0.2906217533159521, Val Loss: 0.3298662454428094\n",
      "Epoch 42/100, Train Loss: 0.29186037289740185, Val Loss: 0.32396394786949984\n",
      "Epoch 43/100, Train Loss: 0.2869403786773523, Val Loss: 0.3070723360761996\n",
      "Epoch 44/100, Train Loss: 0.28526792817539787, Val Loss: 0.31871906680575873\n",
      "Epoch 45/100, Train Loss: 0.28751391948573746, Val Loss: 0.3089602903529451\n",
      "Epoch 46/100, Train Loss: 0.2809698348897909, Val Loss: 0.30602123322305363\n",
      "Epoch 47/100, Train Loss: 0.2856273150415046, Val Loss: 0.3181672054848826\n",
      "Epoch 48/100, Train Loss: 0.28229959474209493, Val Loss: 0.3131825265685\n",
      "Epoch 49/100, Train Loss: 0.27664703436612503, Val Loss: 0.3170590007278647\n",
      "Epoch 50/100, Train Loss: 0.28201126694244494, Val Loss: 0.3237958253175227\n",
      "Epoch 51/100, Train Loss: 0.27707845564723305, Val Loss: 0.3200396212663012\n",
      "Epoch 52/100, Train Loss: 0.2794580718820068, Val Loss: 0.30424349733311856\n",
      "Epoch 53/100, Train Loss: 0.2719991214969333, Val Loss: 0.3151005971643719\n",
      "Epoch 54/100, Train Loss: 0.2714240542982717, Val Loss: 0.30581055486755393\n",
      "Epoch 55/100, Train Loss: 0.2777768700290115, Val Loss: 0.3035560646763309\n",
      "Epoch 56/100, Train Loss: 0.2683202368325349, Val Loss: 0.31627174126303637\n",
      "Epoch 57/100, Train Loss: 0.27200086569156695, Val Loss: 0.2992582551371094\n",
      "Epoch 58/100, Train Loss: 0.2695526212919665, Val Loss: 0.30507316757288533\n",
      "Epoch 59/100, Train Loss: 0.2670334775276423, Val Loss: 0.31785132416952777\n",
      "Epoch 60/100, Train Loss: 0.2672277944872221, Val Loss: 0.29976562361943787\n",
      "Epoch 61/100, Train Loss: 0.25938196547870296, Val Loss: 0.32458322097540365\n",
      "Epoch 62/100, Train Loss: 0.260357971738386, Val Loss: 0.30005204788543477\n",
      "Epoch 63/100, Train Loss: 0.2561916275565183, Val Loss: 0.29298181702243387\n",
      "Epoch 64/100, Train Loss: 0.25738820994260536, Val Loss: 0.3048727098654694\n",
      "Epoch 65/100, Train Loss: 0.2591668567627658, Val Loss: 0.3068255193699198\n",
      "Epoch 66/100, Train Loss: 0.2536293546993644, Val Loss: 0.3017837691220948\n",
      "Epoch 67/100, Train Loss: 0.25873859581660796, Val Loss: 0.2896393888624021\n",
      "Epoch 68/100, Train Loss: 0.25147547927446023, Val Loss: 0.31494317943435735\n",
      "Epoch 69/100, Train Loss: 0.24760815606385564, Val Loss: 0.31156391930533767\n",
      "Epoch 70/100, Train Loss: 0.24945873902692028, Val Loss: 0.2873504372165083\n",
      "Epoch 71/100, Train Loss: 0.2597117533904059, Val Loss: 0.2900000601783333\n",
      "Epoch 72/100, Train Loss: 0.2459999414616966, Val Loss: 0.29187976726064024\n",
      "Epoch 73/100, Train Loss: 0.24121127478796478, Val Loss: 0.2919282349704802\n",
      "Epoch 74/100, Train Loss: 0.24402199965429702, Val Loss: 0.30923061888063574\n",
      "Epoch 75/100, Train Loss: 0.24624895548687994, Val Loss: 0.2923748100357077\n",
      "Epoch 76/100, Train Loss: 0.2473153633452737, Val Loss: 0.2979450486093205\n",
      "Epoch 77/100, Train Loss: 0.2367147676685528, Val Loss: 0.27597275673597843\n",
      "Epoch 78/100, Train Loss: 0.23155739384626672, Val Loss: 0.29404582810686775\n",
      "Epoch 79/100, Train Loss: 0.23156767356681426, Val Loss: 0.2883573659644189\n",
      "Epoch 80/100, Train Loss: 0.23022757746374992, Val Loss: 0.29097740568694686\n",
      "Epoch 81/100, Train Loss: 0.22805394850161473, Val Loss: 0.2786108984752442\n",
      "Epoch 82/100, Train Loss: 0.2302674541812094, Val Loss: 0.28457138468140064\n",
      "Epoch 83/100, Train Loss: 0.22315871219702915, Val Loss: 0.28174935983067984\n",
      "Epoch 84/100, Train Loss: 0.2251554626160175, Val Loss: 0.27464119382419994\n",
      "Epoch 85/100, Train Loss: 0.21894861383130046, Val Loss: 0.2708769894765794\n",
      "Epoch 86/100, Train Loss: 0.21560743208269395, Val Loss: 0.2691285742028086\n",
      "Epoch 87/100, Train Loss: 0.2174812407409122, Val Loss: 0.30804911596174206\n",
      "Epoch 88/100, Train Loss: 0.21517711330739606, Val Loss: 0.28797474093621356\n",
      "Epoch 89/100, Train Loss: 0.2124109492901507, Val Loss: 0.29532824635141325\n",
      "Epoch 90/100, Train Loss: 0.21716925057945835, Val Loss: 0.27399101763110784\n",
      "Epoch 91/100, Train Loss: 0.20747179735572274, Val Loss: 0.27942192730025206\n",
      "Epoch 92/100, Train Loss: 0.20920400775816342, Val Loss: 0.271720076491681\n",
      "Epoch 93/100, Train Loss: 0.2047627459449377, Val Loss: 0.28613563733618935\n",
      "Epoch 94/100, Train Loss: 0.20050550169437947, Val Loss: 0.262425825591881\n",
      "Epoch 95/100, Train Loss: 0.2026221909987591, Val Loss: 0.2838336687082713\n",
      "Epoch 96/100, Train Loss: 0.2038247685251902, Val Loss: 0.2750253448488978\n",
      "Epoch 97/100, Train Loss: 0.19816357576627622, Val Loss: 0.27285748067648086\n",
      "Epoch 98/100, Train Loss: 0.19811058382414082, Val Loss: 0.28505492871189886\n",
      "Epoch 99/100, Train Loss: 0.1963867894443384, Val Loss: 0.2874673228854767\n",
      "Epoch 100/100, Train Loss: 0.19747857521208842, Val Loss: 0.2704673078067437\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the model's accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8913092017173767\n"
     ]
    }
   ],
   "source": [
    "# report model accuracy on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    print(f\"Accuracy: {correct / total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for the sake of curiosity, let's take a random sample from the test set and see the model's prediction. So, randomly choose a sample from the test set and print it out (to see its features and also the correct output). Then, feed the features into your model and see what it predicts. Is it correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.7533, 0.6845, 0.3164, 0.0963]), tensor(6))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "# choose a random sample from test data and print it out\n",
    "sample = test_dataset[random.randint(0, len(test_dataset))]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 6\n"
     ]
    }
   ],
   "source": [
    "# predict the destination of the above sample\n",
    "# print out the prediction\n",
    "_, prediction = torch.max(model(sample[0]).data, -1)\n",
    "print(f\"Predicted: {prediction.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 6\n"
     ]
    }
   ],
   "source": [
    "# print out the actual destination of the above sample\n",
    "print(f\"Actual: {sample[1].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the inverse transform of the encoding you used earlier to get the name of the destination from the predicted class. Print it out and see if it's correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of predicted destination: work\n"
     ]
    }
   ],
   "source": [
    "# use inverse_transform to print out the actual name of destination of the above sample\n",
    "inv = label_enc.inverse_transform([sample[1].item()])\n",
    "print(f\"Name of predicted destination: {inv[0].split('_')[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: What do you think about this approach? Is it a good idea to use Neural Networks for this problem? Why (or why not)? If the patterns in our dataset (passengers' history) get more complicated, will our model be robust to it in comparison to other models?\n",
    "\n",
    "Your Answer: It's obvious that this method was the best one for this problem, we also can see it from the accuracies. It also is so flexible and we can change our nn structure and layers to fit the input data. So overall, despite the heavy preprocessing needed to make a usable data, nn is the best and most reliable method to use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
